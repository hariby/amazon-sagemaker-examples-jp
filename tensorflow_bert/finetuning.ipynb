{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BERT Classification (fine tuning)\n",
    "\n",
    "BERT を使った文書分類のタスクを Amazon SageMaker で動かすためのサンプルです。\n",
    "\n",
    "### 書き換え\n",
    "- TPU 依存している部分を少し修正\n",
    "- `export_savedmodel` で保存\n",
    "- `eval/predict` は消去。\n",
    "  - `predict` 部分は TensorFlow Serving で。\n",
    "- 推論用ファイル読み込み\n",
    "- Managed Spot Training\n",
    "\n",
    "#### あとで書く\n",
    "- GitHub から直接トレーニング\n",
    "- Horovod で複数 GPU 分散学習 [[blog](https://lambdalabs.com/blog/bert-multi-gpu-implementation-using-tensorflow-and-horovod-with-code/)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "print('SageMaker Python SDK Version:', sagemaker.__version__)\n",
    "\n",
    "import os\n",
    "from sagemaker.utils import sagemaker_timestamp\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "default_s3_bucket = sagemaker_session.default_bucket()\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model\n",
    "!wget https://storage.googleapis.com/bert_models/2018_11_23/multi_cased_L-12_H-768_A-12.zip\n",
    "!unzip multi_cased_L-12_H-768_A-12.zip\n",
    "!cp multi_cased_L-12_H-768_A-12/vocab.txt src/\n",
    "    \n",
    "# # download GLUE data\n",
    "# !wget https://gist.githubusercontent.com/W4ngatang/60c2bdb54d156a41194446737ce03e2e/raw/17b8dd0d724281ed7c3b2aeeda662b92809aadd5/download_glue_data.py\n",
    "# !python download_glue_data.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put model and data to S3\n",
    "# model = sagemaker_session.upload_data('uncased_L-12_H-768_A-12', key_prefix='model/bert')\n",
    "model_multi_cased = sagemaker_session.upload_data('multi_cased_L-12_H-768_A-12', key_prefix='model/bert/multi_cased_L-12_H-768_A-12')\n",
    "\n",
    "# data = sagemaker_session.upload_data('glue_data', key_prefix='data')\n",
    "aae_data = sagemaker_session.upload_data('aae_data/aae_questions.csv', key_prefix='data/aae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass to the estimator.fit method\n",
    "train_instance_type='ml.p3.2xlarge'\n",
    "# train_instance_type='ml.c5.2xlarge'\n",
    "# train_instance_type='local_gpu'\n",
    "\n",
    "# model_uncased = '{}/uncased_L-12_H-768_A-12'.format(model_data)\n",
    "# model_multi_cased = '{}/multi_cased_L-12_H-768_A-12'.format(model_data)\n",
    "\n",
    "# glue_data = '{}/glue_data'.format(data)\n",
    "# aae_data = data\n",
    "\n",
    "# pass to the run_classifier.py\n",
    "bert_model_dir = '/opt/ml/input/data/model'\n",
    "# train_dir = '/opt/ml/input/data/train'\n",
    "train_dir = '/opt/ml/input/data/train'\n",
    "\n",
    "estimator = TensorFlow(entry_point=\"run_classifier.py\",\n",
    "                       source_dir='classifier', \n",
    "                       role=role,\n",
    "                       train_instance_count=1,\n",
    "                       train_instance_type=train_instance_type,\n",
    "                       script_mode=True,\n",
    "                       framework_version='1.12',\n",
    "                       py_version='py3',\n",
    "                       base_job_name='BERT-classfication-demo', \n",
    "                       hyperparameters={\n",
    "#                            'task_name': 'MRPC', \n",
    "                           'task_name': 'AAE', \n",
    "                           'do_lower_case': 'true', \n",
    "                           'do_train': 'false', \n",
    "                           'do_eval': 'false', \n",
    "#                            'data_dir': '{}/MRPC'.format(glue_dir), \n",
    "                           'data_dir': train_dir, \n",
    "                           'vocab_file': '{}/vocab.txt'.format(bert_model_dir), \n",
    "                           'bert_config_file': '{}/bert_config.json'.format(bert_model_dir), \n",
    "                           'init_checkpoint': '{}/bert_model.ckpt'.format(bert_model_dir), \n",
    "                           'max_seq_length': '128', \n",
    "                           'train_batch_size': '32', \n",
    "                           'learning_rate': '2e-5', \n",
    "                           'num_train_epochs': '1.0', \n",
    "                           'output_dir': '/opt/ml/checkpoints'\n",
    "                       }, \n",
    "                       \n",
    "#                        train_use_spot_instances=True, \n",
    "#                        train_max_wait = 2*24*60*60, \n",
    "#                        checkpoint_s3_uri='s3://{}/checkpoint/BERT/classification/test/'.format(default_s3_bucket), \n",
    "#                        checkpoint_local_path='/opt/ml/checkpoints'\n",
    "                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# estimator.fit({'glue': glue_data, 'model': model_uncased})\n",
    "estimator.fit({'train': aae_data, 'model': model_multi_cased})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['AI/ML/Analytics', 'コンテナ', 'DB/Storage', 'モバイル/サーバーレス']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.tensorflow.serving import Model\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "model = Model(\n",
    "    model_data=estimator.model_data, \n",
    "    role=role, \n",
    "    entry_point='inference.py', \n",
    "    source_dir='classifier', \n",
    "    framework_version='1.12'\n",
    ")\n",
    "\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m5.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "\n",
    "# text = 'SageMakerでBERTのモデルを動かしたい'\n",
    "text = 'Hello World'\n",
    "\n",
    "result = predictor.predict({\"instances\": text})\n",
    "result\n",
    "print(\"この質問は {} っぽいです。\".format(labels[np.argmax(result['predictions'])]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TensorFlow Serving のデバッグ\n",
    "\n",
    "`!saved_model_cli show --dir export/Servo/<timestamp> --all`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples = []\n",
    "with open('aae_data/aae_questions.csv', mode='rt', encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for (i, line) in enumerate(lines):\n",
    "      example = line.split(',')\n",
    "      label = int(example[0])\n",
    "      text = (example[1])\n",
    "      examples.append(\n",
    "          InputExample(guid=i, text_a=text, label=label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class InputExample(object):\n",
    "  \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
    "\n",
    "  def __init__(self, guid, text_a, text_b=None, label=None):\n",
    "    \"\"\"Constructs a InputExample.\n",
    "\n",
    "    Args:\n",
    "      guid: Unique id for the example.\n",
    "      text_a: string. The untokenized text of the first sequence. For single\n",
    "        sequence tasks, only this sequence must be specified.\n",
    "      text_b: (Optional) string. The untokenized text of the second sequence.\n",
    "        Only must be specified for sequence pair tasks.\n",
    "      label: (Optional) string. The label of the example. This should be\n",
    "        specified for train and dev examples, but not for test examples.\n",
    "    \"\"\"\n",
    "    self.guid = guid\n",
    "    self.text_a = text_a\n",
    "    self.text_b = text_b\n",
    "    self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "examples[0].text_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
